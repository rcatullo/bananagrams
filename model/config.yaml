model:
  image_encoder:
    backbone: "resnet50"
    pretrained: true
    freeze: true
    
  text_encoder:
    model_name: "ViT-B/32"  # CLIP model variant
    freeze: true
    
  # Cross-attention fusion
  fusion:
    hidden_dim: 512  # Dimension for cross-attention
    num_layers: 4  # Number of cross-attention layers
    num_heads: 8  # Number of attention heads
    dropout: 0.1
    
  decoder:
    base_channels: 64
    use_skip_connections: true

training:
  batch_size: 16  # Adjust based on GPU memory
  num_epochs: 50
  learning_rate: 1.0e-4
  weight_decay: 1.0e-4
  optimizer: "adamw"  # adamw, adam, sgd
  
  lr_scheduler: "cosine"  # cosine, step, plateau, none
  warmup_epochs: 5
  min_lr: 1.0e-6
  
  use_amp: true  # Automatic Mixed Precision for faster training
  
  max_grad_norm: 1.0  # Gradient clipping
  
  val_every_n_epochs: 1
  
  checkpoint_dir: "checkpoints"
  save_every_n_epochs: 5
  keep_last_n_checkpoints: 3
  save_best_only: true  # Save best model by validation IoU

loss:
  bce_weight: 1.0  # Binary cross-entropy weight
  dice_weight: 1.0  # Dice loss weight
  
data:
  image_size: 512  # Input resolution (square images)
  normalize_mean: [0.485, 0.456, 0.406]  # ImageNet normalization
  normalize_std: [0.229, 0.224, 0.225]
  
  num_train_samples: 2048  # 8 shards × 256 samples
  num_val_samples: 256 # 1 shard × 256 samples
  num_test_samples: 256 # 1 shard × 256 samples
  
  # Dataset paths (supports both local and S3)
  # For S3: use s3://bucket-name/prefix format
  # For local: use relative or absolute path
  data_root: "s3://pico-banana-400k/processed/webdataset"
  train_shards: "train/shard-{000000..000007}.tar"  # Pattern for train shards (8 shards)
  val_shards: "train/shard-{000004..000007}.tar"  # Use last training shard for validation (temporary)
  test_shards: "train/shard-{000004..000007}.tar"  # Use last training shard for test (temporary)
  
  # For local testing, uncomment:
  #data_root: "../dataset/tmp_shards"
  #train_shards: "shard-000000.tar"
  #val_shards: "shard-000000.tar"
  #test_shards: "shard-000000.tar"
  
  num_workers: 4  # Set to 0 for local testing with single shard, increase for AWS
  prefetch_factor: 2
  pin_memory: true
  
  augmentation:
    enabled: true
    random_horizontal_flip: 0.5
    random_vertical_flip: 0.0
    color_jitter:
      brightness: 0.1
      contrast: 0.1
      saturation: 0.1
      hue: 0.05
    random_rotation: 0  # Degrees (0 = disabled)
    random_scale: [0.9, 1.1]  # Scale range for random zoom

logging:
  log_dir: "logs"
  experiment_name: "mask_model"
  
  use_tensorboard: true
  tensorboard_dir: "runs"
  
  log_every_n_steps: 10
  log_images_every_n_steps: 100
  num_images_to_log: 4

evaluation:
  batch_size: 16
  metrics:
    - "iou"
    - "f1"
    - "precision"
    - "recall"
    - "accuracy"
  threshold: 0.5  # Threshold for binary prediction

system:
  device: "cuda"  # cuda, cpu, or specific device like cuda:0
  seed: 42
  deterministic: false  # Set true for reproducibility (may impact performance)
  num_threads: 4  # Number of CPU threads for torch operations

